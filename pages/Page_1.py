import streamlit as st

st.set_page_config(
    page_title="Modeling Pipeline",
    page_icon="ü§ñ",
    layout="wide"
)

st.title("ü§ñ Double-Residual Machine Learning (DML) Pipeline")
st.write("""
This page documents the full modeling workflow used in our project, including the 
four core modules that implement the **Double-Residual Machine Learning (DML)** method.
This pipeline ensures unbiased estimation of the effect of contextual (bias) variables 
on NBA contract value after controlling for on-court performance.
""")

st.markdown("---")

# =========================================
# SECTION 1 ‚Äî HIGH-LEVEL PIPELINE
# =========================================
st.header("üìê Overview of the Modeling Workflow")

st.write("""
Our analysis follows the Double-Residual Machine Learning (DML) framework.  
The full pipeline consists of four modules:

1. **Outcome Model (Module 1)** ‚Äî Predict Salary from Performance  
2. **Treatment Models (Module 2)** ‚Äî Predict Bias Factors from Performance  
3. **DML Cross-Fitting Engine (Module 3)** ‚Äî Generate out-of-sample residuals  
4. **Final OLS Bias Model (Module 4)** ‚Äî Regress residuals on residuals to estimate bias  

This structure ensures that contextual variables (nationality, draft status, age, etc.)  
are tested **only on the part of salary they cannot explain by performance alone**.
""")

st.markdown("---")

# =========================================
# MODULE 1
# =========================================
st.header("üìò Module 1 ‚Äî Outcome Model  \n *f(X) = Salary ~ Performance*")

st.write("""
**Goal:** Predict a player's market salary based only on their performance metrics (X).  
This isolates the "expected" salary given on-court value.

**Input:**  
- `X_train` ‚Üí Performance statistics  
- `y_train` ‚Üí Salary (log-transformed or raw)

**Output:**  
- A trained model with `.predict()`  
- Used to compute **epsilon_Y = Y - ≈∑** (salary residuals)

**Current Model:**  
- Random Forest Regressor (simple to tune, handles nonlinearities)  
- Wrapped inside our `train_f_model` function  
- Tuned using GridSearchCV (but can be swapped for linear/Ridge/Lasso later)

**Why this matters:**  
This residual (epsilon_Y) represents **salary mispricing** ‚Äî the under/overpay relative to a player‚Äôs performance.
""")

st.code("""
def train_f_model(X_train, y_train):
    \"\"\"Trains outcome model f: Y ~ X (Salary ~ Performance).\"\"\"
    return model_f
""", language="python")

st.markdown("---")

# =========================================
# MODULE 2
# =========================================
st.header("üìô Module 2 ‚Äî Treatment Models  \n *h_j(X) = Bias Factors ~ Performance*")

st.write("""
**Goal:** Predict each contextual/bias variable (Z·±º) using only performance metrics (X).  
Examples of Z include:
- Draft Position  
- Age  
- Nationality  
- Team Market Size  
- Role/Position  
- Minutes per game context  
- Team salary cap / owner wealth

Each Z·±º gets **its own model**, trained independently.

**Input:**  
- `X_train` ‚Üí Performance features  
- `Z_train` ‚Üí Bias/contextual variables  

**Output:**  
- Dictionary of models `{Z_j: model_h_j}`  
- Used to compute **epsilon_Z_j = Z_j - ZÃÇ_j**

**Why this matters:**  
This step removes the part of each bias factor that is *explained* by performance.  
What remains is the ‚Äúpure‚Äù bias component.
""")

st.code("""
def train_h_models(X_train, Z_train):
    \"\"\"Trains one treatment model h_j for each bias factor Z_j.\"\"\"
    return models_h
""", language="python")

st.markdown("---")

# =========================================
# MODULE 3
# =========================================
st.header("‚öôÔ∏è Module 3 ‚Äî DML Cross-Fitting Engine")

st.write("""
This is the **core engine** of the pipeline.  
It implements the K-fold cross-fitting algorithm described in Section 6 of our methodology.

**What it does:**

1. Creates K folds (default K=5)  
2. For each fold:  
   - Trains f and h·±º models on the training split  
   - Predicts f(X) and h·±º(X) on the out-of-sample (OOS) split  
3. Stores residuals only from OOS predictions  
4. After all folds, concatenates residuals into full-series vectors  

**Output:**  
- Œµ·µß (OOS salary residuals)  
- Œµùëç (OOS bias residuals, one column per Z variable)

These ‚Äúclean‚Äù residuals feed into the final OLS step.
""")

st.code("""
def generate_dml_residuals(X, Y, Z, model_f_trainer, model_h_trainer, k_folds=5):
    \"\"\"Main residual-generation engine for DML cross-fitting.\"\"\"
    return residuals_Y_oos, residuals_Z_oos
""", language="python")

st.markdown("---")

# =========================================
# MODULE 4
# =========================================
st.header("üìó Module 4 ‚Äî Final Debiased OLS Regression")

st.write("""
The final step estimates the effect of contextual variables (Z) on mispricing (Y residuals):

### **Œµ·µß = Œ≤‚ÇÄ + Œ≤‚ÇÅ ŒµZ‚ÇÅ + Œ≤‚ÇÇ ŒµZ‚ÇÇ + ... + Œ≤‚Çñ ŒµZ‚Çñ + u**

Because both sides are **residualized**, the resulting coefficients are *debiased*  
and represent the true causal contribution of each factor to contract misvaluation.

**Output:**  
- Statsmodels regression object  
- Coefficients, p-values, standard errors  
- Interpretability for bias analysis  

**This is where the ‚Äúbias effects‚Äù are measured.**
""")

st.code("""
def run_final_ols(residuals_Y, residuals_Z):
    \"\"\"Runs final OLS: epsilon_Y ~ epsilon_Z.\"\"\"
    return results
""", language="python")

st.markdown("---")

# =========================================
# SUMMARY BLOCK
# =========================================
st.header("‚úÖ Summary")

st.write("""
Our DML pipeline ensures:

- ‚úî Correct handling of high-dimensional performance metrics  
- ‚úî Separation of performance effects from contextual variables  
- ‚úî Unbiased estimation of contract bias  
- ‚úî Modular design (each model easily replaceable)  
- ‚úî Full reproducibility through cross-fitting  

This modeling system forms the backbone of our project‚Äôs analysis of NBA salary inefficiency 
and structural bias.
""")
