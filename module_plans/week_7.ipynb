{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a3b0239",
   "metadata": {},
   "source": [
    "Ah, my apologies\\! You're right, no need for a file when you just want the content. Here is the plan from the notebook, formatted as a series of markdown and code blocks that you can copy directly.\n",
    "\n",
    "-----\n",
    "\n",
    "# Week 7 - Action Plan: Enhancements & Visualization\n",
    "\n",
    "This document outlines the concrete tasks for the three main themes of this week's work.\n",
    "\n",
    "## Theme 1: Model Modification (Improving Accuracy)\n",
    "\n",
    "**Goal:** Improve the accuracy of our nuisance models (`f_model: Y~X` and `h_models: Z_j~X`). More accurate models produce cleaner residuals, which leads to a more reliable and precise final OLS estimate (`gamma`).\n",
    "\n",
    "**Assigned to:** .\n",
    "\n",
    "### Task 1.A: Implement Hyperparameter Tuning\n",
    "\n",
    "Instead of using a simple `OLS`, we should tune our models. The tuning *must* happen *inside* the cross-fit loop on the *training data for that fold*.\n",
    "\n",
    "  * **Action (for `src/analysis/train_f_model.py`):**\n",
    "\n",
    "    1.  Inside the `train_f_model` function, replace the simple `model.fit()` with a `GridSearchCV` or `RandomizedSearchCV`.\n",
    "\n",
    "    2.  Define a parameter grid for your chosen model (e.g., `RandomForestRegressor`).\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```python\n",
    "# Example for RandomForest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_leaf': [1, 3]\n",
    "}\n",
    "# Use a 3-fold CV for tuning, and use all available cores\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=3, \n",
    "    n_jobs=-1,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "# grid_search.fit(X_train, Y_train) # This would be run inside your function\n",
    "\n",
    "# The .best_estimator_ is already re-fitted on the whole (X_train, Y_train)\n",
    "# return grid_search.best_estimator_\n",
    "```\n",
    "\n",
    "  * **Action (for `src/analysis/train_h_models.py`):**\n",
    "\n",
    "    1.  Apply the *exact same logic* inside the `for` loop in `train_h_models`. Each `h_model` (for Age, Draft \\#, etc.) will be individually tuned on each fold. This will be more computationally intensive but much more robust.\n",
    "\n",
    "### Task 1.B: Experiment with More Powerful Models\n",
    "\n",
    "  * **Action:** Try a more powerful model for tabular data, like `GradientBoostingRegressor` or `XGBoost`.\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```python\n",
    "# Example for GradientBoosting\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "```\n",
    "\n",
    "## Theme 2: Investigating Deterministic Rules\n",
    "\n",
    "**Goal:** Our `f_model` (Salary \\~ Performance) will be very inaccurate for players on deterministic contracts (e.g., rookies), where salary is set by `DRAFT_NUMBER`, not `PIE`. This inaccuracy pollutes your `epsilon_Y` residual. We must \"help\" the `f_model` by telling it about these rules.\n",
    "\n",
    "**The Solution:** We will *control* for these deterministic effects by adding them to the `X` (controls) matrix. This moves them from \"unexplained\" to \"explained,\" giving us a cleaner \"unexplained\" residual.\n",
    "\n",
    "  * **Action (for `main.py` -\\> `preprocess_data` function):**\n",
    "\n",
    "    1.  Create new feature flags for these deterministic groups.\n",
    "\n",
    "    2.  Add this logic inside `preprocess_data`, *after* handling NaNs for draft:\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```python\n",
    "# ... inside preprocess_data(df) ...\n",
    "\n",
    "# 3. Handle missing DRAFT* ... (already done)\n",
    "\n",
    "# 3.5. Engineer Deterministic Contract Flags\n",
    "logging.info(\"Engineering deterministic contract flags...\")\n",
    "\n",
    "# Flag for players on 1st round rookie scale (e.g., drafted in last 4 years)\n",
    "# Adjust '2021' as needed for your data's \"current season\"\n",
    "proc_df['is_rookie_scale'] = (\n",
    "    (proc_df['DRAFT_YEAR'] >= 2021) & \n",
    "    (proc_df['DRAFT_ROUND'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Flag for undrafted players (using our imputed value)\n",
    "proc_df['is_undrafted'] = (proc_df['DRAFT_ROUND'] == 3).astype(int)\n",
    "\n",
    "# Flag for \"Max Contract\" players (This is an approximation)\n",
    "# Find the 95th percentile salary and flag anyone above it.\n",
    "max_contract_threshold = proc_df['log_Salary'].quantile(0.95)\n",
    "proc_df['is_max_contract'] = (\n",
    "    proc_df['log_Salary'] > max_contract_threshold\n",
    ").astype(int)\n",
    "```\n",
    "\n",
    "  * **Action (for `main.py` -\\> `CONFIG`):**\n",
    "\n",
    "    1.  Add these new columns to your `X_COLUMNS` list. This tells the `f_model` to use them as controls.\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```python\n",
    "# ... inside CONFIG ...\n",
    "\"X_COLUMNS\": [\n",
    "    'OFF_RATING', 'DEF_RATING', # ..., 'FGM_PG', 'FGA_PG',\n",
    "    # New deterministic controls:\n",
    "    'is_rookie_scale',\n",
    "    'is_undrafted',\n",
    "    'is_max_contract'\n",
    "],\n",
    "```\n",
    "\n",
    "This change will make your `f_model` *much* more accurate, as it can now learn \"This player is a new hire? Their salary is *this*, regardless of performance.\" The `epsilon_Y` residual will now represent the \"salary unexplained by *both* performance *and* deterministic contract rules,\" which is a much cleaner target for your final analysis.\n",
    "\n",
    "## Theme 3: Visualization (The Final Presentation)\n",
    "\n",
    "**Goal:** Create an interactive, web-based presentation of your findings.\n",
    "\n",
    "**Tool:** Streamlit is the perfect choice. It's 100% Python and integrates perfectly with Pandas and Plotly.\n",
    "\n",
    "### Task 3.A: Save Data for the App\n",
    "\n",
    "Your Streamlit app needs the final residuals. \n",
    "\n",
    "### Task 3.B: Brainstorm Streamlit App (`presentation.py`)\n",
    "\n",
    "Create a new file, `presentation.py`. Here is a full-fledged brainstorm for what it could contain.\n",
    "\n",
    "  * **Page 1: The \"Naive\" View**\n",
    "\n",
    "      * **Title:** NBA Salary: Performance vs. Perception\n",
    "\n",
    "      * **Intro:** \"Our project investigates what *really* determines an NBA player's salary. We all know performance matters, but what about 'bias' factors like age, draft pick, or social media fame?\"\n",
    "\n",
    "      * **Viz 1: The Noisy Relationship:**\n",
    "\n",
    "          * Show a `plotly.express.scatter` plot of `log_Salary` vs. `PIE`.\n",
    "\n",
    "          * **Make it interesting:** Use `color='AGE'` and `size='Followers'`.\n",
    "\n",
    "          * **Point:** \"This is a *mess*\\! It's hard to see a clear trend because performance (PIE) is tangled up with other factors. For example, young players (blue dots) have high performance but low pay (rookie contracts).\"\n",
    "\n",
    "  * **Page 2: Our Method (DML Explained Simply)**\n",
    "\n",
    "      * **Title:** How We Untangle the Mess\n",
    "\n",
    "      * **Viz 2: A Simple Diagram:**\n",
    "\n",
    "          * \"We use a method called Double Machine Learning (DML) to isolate the *true* relationships.\"\n",
    "\n",
    "          * **Box 1:** \"Salary ($Y$)\" -\\> \"Cleaned Salary ($\\epsilon_Y$)\" (by removing all `X` Performance effects)\n",
    "\n",
    "          * **Box 2:** \"Age ($Z$)\" -\\> \"Cleaned Age ($\\epsilon_Z$)\" (by removing all `X` Performance effects)\n",
    "\n",
    "          * **Final Step:** Compare \"Cleaned Salary\" vs. \"Cleaned Age\".\n",
    "\n",
    "  * **Page 3: The \"Money\" Charts (The Debias-ed Results)**\n",
    "\n",
    "      * **Title:** The *True* Effect of Bias\n",
    "\n",
    "      * **Intro:** \"After cleaning our data, here is what we found. These charts show the *true*, *debiased* relationship between our factors and salary, after *all* on-court performance is accounted for.\"\n",
    "\n",
    "      * **Viz 3: The Final OLS (The *real* result\\!)**\n",
    "\n",
    "          * Load `dml_residuals_for_viz.csv`.\n",
    "\n",
    "          * Add a `st.selectbox` to let the user choose which Z-factor to view: `['AGE', 'DRAFT_NUMBER', 'Followers', 'COUNTRY_USA']`.\n",
    "\n",
    "          * Based on the selection, show the scatter plot:\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```python\n",
    "import plotly.express as px\n",
    "\n",
    "selected_z = 'AGE' (from selectbox)\n",
    "z_col = f'residual_{selected_z}'\n",
    "fig = px.scatter(df_viz, \n",
    "                x=z_col, \n",
    "                y='residual_Y', \n",
    "                trendline='ols',\n",
    "                hover_data=['PLAYER_NAME', 'log_Salary', selected_z])\n",
    "fig.update_layout(\n",
    "    title=f\"Debiased Effect of {selected_z} on log(Salary)\",\n",
    "    xaxis_title=f\"Residual {selected_z} (Performance-Adjusted)\",\n",
    "    yaxis_title=\"Residual log(Salary) (Performance-Adjusted)\"\n",
    ")\n",
    "st.plotly_chart(fig)\n",
    "```\n",
    "\n",
    "  * **How to make it interesting:** The `hover_data` is key. A user can mouse over an outlier dot and see \"LeBron James\" or \"Victor Wembanyama\" and see how their real vs. residual values stack up.\n",
    "\n",
    "  * **Page 4: Conclusions & Full Results**\n",
    "\n",
    "      * **Title:** Final Coefficients\n",
    "\n",
    "      * **Viz 4: The Summary Table:**\n",
    "\n",
    "          * Load and parse `final_dml_regression_summary.txt`.\n",
    "\n",
    "          * Display the OLS results table in a clean `st.dataframe` or `st.code`.\n",
    "\n",
    "          * **Interpretation:** Write out in plain English what your `gamma` coefficients mean.\n",
    "\n",
    "          * **Example:** \"Our model finds that for every 1-unit increase in 'Performance-Adjusted Followers', a player's 'Performance-Adjusted log(Salary)' increases by **{gamma\\_followers}**. This effect is statistically significant (p \\< 0.05).\"\n",
    "\n",
    "This 4-page Streamlit app tells a complete and compelling story, from the \"naive\" problem to your sophisticated DML solution and the final, interpretable results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed8145e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
